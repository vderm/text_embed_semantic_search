---
author:
- Vasken Dermardiros
categories: website
draft: false
lastmod: 2020-07-17 08:57:04-04:00
tags:
- causality
- research
- uncertainty
- model
- revisit
title: Causality
---


## Spurious Correlations {#spurious-correlations}

author: Murat Kocaoglu?

<https://www.tylervigen.com/spurious-correlations>

![[2020-06-09_22-24-27_screenshot.png]]


## Causal Learning for Decision Making (CLDM) {#causal-learning-for-decision-making--cldm}

<https://causalrlworkshop.github.io/index.html>


## Causality: From Learning to Generative Models {#causality-from-learning-to-generative-models}

MIT-IBM Watson AI Lab
<https://diro.umontreal.ca/departement/colloques/colloque/news/eventDetail/Event/causality-from-learning-to-generative-models-murat-kocaoglu/>
<http://www.muratkocaoglu.com/>

Causal inference is fundamental for multiple disciplines ranging from medical
research to engineering, statistics and economics. It is also central in machine
learning and is now becoming a core component of artificial intelligence
research. Although causal inference has been studied for a long time in various
fields under different frameworks, today we need tools that can process a large
number of variables to handle modern large datasets. The graphical approach to
probabilistic causation advocated by Judea Pearl and others provides a way to
compactly represent the causal relations using directed acyclic graphs and paves
the way for the design of algorithms that can answer causal questions for many
variables.

In this talk, I first provide a friendly introduction to causality and explain
why causal understanding is important. As my first contribution, I propose a
framework called entropic causal inference for inferring the causal direction
between two variables from data. I show that entropy can be used to capture the
complexity of a causal mechanism. Further, if the true direction has a simple
mechanism, we can identify it from data. The entropic causal inference framework
leverages tools from information theory for causal inference. As my second
contribution, I show how we can apply causality in deep generative models - deep
neural networks used for modeling complex data. I demonstrate how to define and
train a causal deep generative model, called CausalGAN for generating images
with labels. As an extension of generative adversarial networks (GANs),
CausalGAN allows sampling not only from the observed data distribution but also
from the interventional distributions of images. I conclude with future
directions for causal inference and its applications in supervised learning and
reinforcement learning.


## Invariant Risk Minimization {#invariant-risk-minimization}

<sup id="2194d04d0eb6a17f72e3f10975c147ca"><a href="#Arjovsky_InvariantRiskMinimization_2019" title="Arjovsky, Bottou, Gulrajani \&amp; Lopez-Paz, Invariant {{Risk Minimization}}, v(), 31 (2019).">Arjovsky_InvariantRiskMinimization_2019</a></sup>
[[Arjovsky_InvariantRiskMinimization_2020]]

Follow up on the paper, many details I have to reread to better understand...


### Discussion with Emilio {#discussion-with-emilio}

He suggested I watch the between Gary Marcus and Yoshua Bengio, which is in the AI [[debate-bengio-marcus]]

![[2020-06-15_10-47-41_screenshot.png]]

![[2020-06-15_10-48-02_screenshot.png]]

![[2020-06-15_10-51-03_screenshot.png]]


## To Build Truly Intelligent Machines, Teach Them Cause and Effect {#to-build-truly-intelligent-machines-teach-them-cause-and-effect}

- <https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515/>

Judea Pearl invented Bayesian nets which got him a Turing award. Net is useful
to say "if a person comes back from Africa with a fever and body aches, the most
likely explanation was malaria."

He has a new book called [The Book of Why](https://www.basicbooks.com/titles/judea-pearl/the-book-of-why/9780465097609/).

“All the impressive achievements of deep learning amount to just curve fitting,”
he said recently with the machines unable to really understand cause and effect.


## Causality for Machine Learning {#causality-for-machine-learning}

Very interesting [website](https://ff13.fastforwardlabs.com/)!

[//begin]: # "Autogenerated link references for markdown compatibility"
[[2020-06-09_22-24-27_screenshot.png]: ../attachments/Spurious_Correlations/2020-06-09_22-24-27_screenshot.png "2020-06-09_22-24-27_screenshot.png"
[Arjovsky_InvariantRiskMinimization_2020]: ../articles/Arjovsky_InvariantRiskMinimization_2020.md "Arjovsky_InvariantRiskMinimization_2020: Invariant Risk Minimization"
[debate-bengio-marcus]: debate-bengio-marcus.md "AI Debate: Gary Marcus and Yoshua Bengio"
[[2020-06-15_10-47-41_screenshot.png]: ../attachments/Invariant_Risk_Minimization/2020-06-15_10-47-41_screenshot.png "2020-06-15_10-47-41_screenshot.png"
[[2020-06-15_10-48-02_screenshot.png]: ../attachments/Invariant_Risk_Minimization/2020-06-15_10-48-02_screenshot.png "2020-06-15_10-48-02_screenshot.png"
[[2020-06-15_10-51-03_screenshot.png]: ../attachments/Invariant_Risk_Minimization/2020-06-15_10-51-03_screenshot.png "2020-06-15_10-51-03_screenshot.png"
[//end]: # "Autogenerated link references"