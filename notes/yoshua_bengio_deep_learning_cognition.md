---
author:
- Yoshua Bengio
categories: website
draft: false
lastmod: 2020-12-23 09:04:00-05:00
slug: yoshua_bengio_deep_learning_cognition
tags:
- programming
- causality
- research
title: 'Yoshua Bengio: Deep Learning Cognition'
links:
- https://www.youtube.com/watch?v=GibjI5FoZsE
---

[[thinking-fast-and-slow]]

video
: <https://www.youtube.com/watch?v=GibjI5FoZsE>

## To get to AI, need to figure out certain fundamentals {#to-get-to-ai-need-to-figure-out-certain-fundamentals}

![[2020-12-22_23-49-25_screenshot.png]]

## Some believe we're done with AI, just need to scale {#some-believe-we-re-done-with-ai-just-need-to-scale}

Not so fast!

- Sample complexity is lacking relative to humans.
- We tell the machines what to look for
- Babies learn by themselves, intuition
- Errors machines make are not like what we do
  - Cows on a beach example
- Deep learning is great but what's the next thing?
  - Distributed representations
  - Hierarchical
  - Optimization methods

![[2020-12-22_23-51-07_screenshot.png]]

![[2020-12-22_23-56-33_screenshot.png]]

Humans can generalize beyond the training data, we can combine pieces of data of
past experiences together and imagine a solution: systematic generalization,
system-2 reasoning. System-1 are things we know but can't communicate.

We don't deal with causality well. Joint distribution isn't sufficient to
recover this.

Common sense is missing too. (System 1 knowledge)

## Deep Learning idea {#deep-learning-idea}

Original idea was to have a large hierarchy so that the higher levels would be
abstracted in the way how humans think. Disentangled representations.

![[2020-12-23_00-07-07_screenshot.png]]

![[2020-12-23_00-07-38_screenshot.png]]

How we think about a door isn't really about what it looks like, how it works
but what it does and how we interact/act with/on them. A chair is something you
sit on, don't care much about what it looks like.

Attention one of key ideas to unlock this behaviour. It is selective and it is
learnable, no need for rules and heuristics to program.

![[2020-12-23_00-10-37_screenshot.png]]

Memory and credit assignment through time.

A potential solution to the vanishing gradient problem...

![[2020-12-23_00-17-15_screenshot.png]]

After something happened, driving and herd a pop, you keep driving until you get
to a gas station where you realize you had a flat. You then think back to when
the flat happened and from now on, if you hear a pop, you should stop.
Basically, although a lot of things happened since the pop, you play back your
memory up to that event and focus your attention there.

## System 1 and System 2 cognitive processing {#system-1-and-system-2-cognitive-processing}

References the [[notes/thinking-fast-and-slow]] book.

- System 1: intuitive, fast, automatic, anchored in perception (unconscious)
  - What current deep learning is very good at
- System 2: rational, sequential, slow, logical, conscious, expressible with
    language (conscious)
  - What future deep learning needs to do better

![[2020-12-23_08-44-46_screenshot.png]]

![[2020-12-23_08-45-47_screenshot.png]]

![[2020-12-23_08-48-32_screenshot.png]]

## Computationality {#computationality}

![[2020-12-23_08-55-44_screenshot.png]]

One of the papers they've worked on is the "Residual independent mechanisms"
(RIM). It is a drop-in replacement to a GRU. Tends to do better with OoD.

![[2020-12-23_08-57-45_screenshot.png]]

Running on sets of vectors instead of vectors. Transformers do this already. Set
processing instead of sequence processing.

How do we discover causal relationships? The world changes based on actions of
agents.

![[2020-12-23_09-00-27_screenshot.png]]

Good representations can lead to faster generalization. Can we learn these good
representations?

[notes/thinking-fast-and-slow]: thinking-fast-and-slow.md "Thinking, Fast and Slow"

[//begin]: # "Autogenerated link references for markdown compatibility"
[thinking-fast-and-slow]: thinking-fast-and-slow.md "Thinking, Fast and Slow"
[[2020-12-22_23-49-25_screenshot.png]: ../attachments/2020-12-22_23-49-25_screenshot.png "2020-12-22_23-49-25_screenshot.png"
[[2020-12-22_23-51-07_screenshot.png]: ../attachments/Some_believe_we're_done_with_AI,_just_need_to_scale/2020-12-22_23-51-07_screenshot.png "2020-12-22_23-51-07_screenshot.png"
[[2020-12-22_23-56-33_screenshot.png]: ../attachments/Some_believe_we're_done_with_AI,_just_need_to_scale/2020-12-22_23-56-33_screenshot.png "2020-12-22_23-56-33_screenshot.png"
[[2020-12-23_00-07-07_screenshot.png]: ../attachments/Deep_Learning_idea/2020-12-23_00-07-07_screenshot.png "2020-12-23_00-07-07_screenshot.png"
[[2020-12-23_00-07-38_screenshot.png]: ../attachments/Deep_Learning_idea/2020-12-23_00-07-38_screenshot.png "2020-12-23_00-07-38_screenshot.png"
[[2020-12-23_00-10-37_screenshot.png]: ../attachments/Deep_Learning_idea/2020-12-23_00-10-37_screenshot.png "2020-12-23_00-10-37_screenshot.png"
[[2020-12-23_00-17-15_screenshot.png]: ../attachments/Deep_Learning_idea/2020-12-23_00-17-15_screenshot.png "2020-12-23_00-17-15_screenshot.png"
[notes/thinking-fast-and-slow]: thinking-fast-and-slow.md "Thinking, Fast and Slow"
[[2020-12-23_08-44-46_screenshot.png]: ../attachments/System_1_and_System_2_cognitive_processing/2020-12-23_08-44-46_screenshot.png "2020-12-23_08-44-46_screenshot.png"
[[2020-12-23_08-45-47_screenshot.png]: ../attachments/System_1_and_System_2_cognitive_processing/2020-12-23_08-45-47_screenshot.png "2020-12-23_08-45-47_screenshot.png"
[[2020-12-23_08-48-32_screenshot.png]: ../attachments/System_1_and_System_2_cognitive_processing/2020-12-23_08-48-32_screenshot.png "2020-12-23_08-48-32_screenshot.png"
[[2020-12-23_08-55-44_screenshot.png]: ../attachments/Compositionality/2020-12-23_08-55-44_screenshot.png "2020-12-23_08-55-44_screenshot.png"
[[2020-12-23_08-57-45_screenshot.png]: ../attachments/Computationality/2020-12-23_08-57-45_screenshot.png "2020-12-23_08-57-45_screenshot.png"
[[2020-12-23_09-00-27_screenshot.png]: ../attachments/Computationality/2020-12-23_09-00-27_screenshot.png "2020-12-23_09-00-27_screenshot.png"
[//end]: # "Autogenerated link references"